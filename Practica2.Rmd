---
title: 'Tipologia i cicle de vida de les dades: Pràctica 2'
author: "Autors: Jonathan Mir Fernández-Aramburu i Dario Cabrera Gurillo"
date: "Maig 2022"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
  pdf_document: 
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(out.width="250px", dpi=100, warning = FALSE)
```
******
# Descripció del dataset

En aquest treball realitzarem un estudi sobre el dataset [Red Wine Quality](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009), el qual tenim disponible a la plataforma de kaggle i correspon al conjunt de dades originari del repositori *UCI machine learning repository*.

El dataset conté informació de diverses variants del vi portugués “Vinho Verde”, incloent variables quantitatives com medicions Fisico-químiques i sensorials (qualitat del vi).Tanmateix per raons de privacitat i secret comercial s’exclouen dades comercials com la marca, el preu o el tipus de raïm emprat en l’elaboració dels vins. 

Aquest dataset pot ser emprat per determinar quins factors fisicoquímics defineixen un bon vi, responent a les següents preguntes: 

- Hi ha una combinació específica en les propietats Fisico-químiques que facin un vi de la millor qualitat? 
- És un factor o hi ha diversos? 
- Com és relacionen entre sí? 
- Quines són les seves distribucions estadístiques?

El dataset conté 12 variables, on les 11 primeres poden considerar-se els inputs (factors Fisico-químics) i la última l’output (valoració de la qualitat del vi basada en una experiència sensorial) dins del rang $[1,10]$.

Carreguem a continuació els paquets necessaris en R per tal de fer les anàlisi corresponents:

```{R message=FALSE, warning=FALSE}
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require('nortest')) install.packages('nortest'); library('nortest')
if (!require('corrplot')) install.packages('corrplot'); library('corrplot')
if (!require('doBy')) install.packages('doBy'); library('doBy')
if (!require('caret')) install.packages('caret'); library('caret')
if (!require('tidyr')) install.packages('tydir'); library('tidyr')
if (!require('DescTools')) install.packages('DescTools'); library('DescTools')
if (!require('pROC')) install.packages('pROC'); library('pROC')
if (!require('rminer')) install.packages('rminer'); library('rminer')
if (!require('C50')) install.packages('C50'); library('C50')
````


******
# Integració i selecció de dades a analitzar.

Donat que resulta fonamental conèixer el domini de les dades que pretenem analitzar i modelitzar passem a descriure-les a continuació:

1. **Fixed acitidy**: Quantitat d'àcids implicats al vi. La majoria dels àcids en el vi són fixos, és a dir, no s’evaporen fàcilment.

2. **volatile acidity**: Quantitat d'àcid acètic al vi. En altes quantitats, pot provocar un gust desagradable.

3. **citric acid**: Quantitat d'àcid cítric. Concentrat en petites quantitats, pot aportar frescor i sabor als vins.

4. **residual sugar:** La quantitat de sucre remanent un cop finalitzada la fermentació. Resulta estrany trobar vins amb menys d’un gram per litre. Vins amb més de 45 grams/litre són considerats dolços. 

5. **Chlorides:** Quantitat de sal en el vi.

6. **Free sulfur dioxide:** SO2 en forma lliure existent en equilibri amb el SO2 mol·lecular (dissolt com un gas). És un element que impedeix el creixement bacterià i l'oxidació del vi. 

7. **Total sulfur dioxide:** Quantitat total SO2. Encara que és necesari per a evitar la oxidació, en concentracions superiors als 50 ppm  desbarata el gust i l'olor del vi. 

8. **density:** Densitat del líquid en relació a la quantitat d’alcohol i sucre. Els vins solen ser un 8\% més densos que l'aigua.

9. **pH:** Valor numèric que ens diu el grau d'acidesa o alcalinitat del vi. Descriu quan àcid o bàsic és un vi d’una escala des de 0 (molt àcid) a 14 (molt bàsic). La majoria de vins es situen entre 3 i 4. 

10. **sulphates:** Quantitat d'additiu que actua com a antibacterià i antioxidant.

11. **Alcohol:** Percentatge d'alcohol present al vi. 

12. **quality:** Variable output qualitativa basada en dades sensorials, en una escala de $[1,10]$. 

Per l’anàlisi que volem realitzar considerem que podem mantenir les 12 variables, per tant, no farem cap subselecció.

A continuació carreguem les dades a partir del csv descarregat a [Kaggle](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009):

````{R carrega de dades videojocs}
library(readr)
B_vi <- read.csv("winequality-red.csv", sep= ",", header= TRUE, dec=".")
````


# Neteja de les dades
## Exploració del conjunt de dades

L'exploració inicial de les dades resulta fonamental per tenir una noció del domini de cada variable.
Efectuarem a continuació una exploració preliminar del conjunt de dades, imprimint la capçalera amb un conjunt d'observacions:

````{R Exploracio 1}
str(B_vi)
````

Veiem que tenim un total de 1599 registres amb 12 variables.

Podem verificar a més les distribucions de les nostres variables tenint en compte estadístics com el mínim, els quartils (i mitjana) i el màxim, junt amb la mitja:

````{R Exploracio 2}
summary(B_vi)
````

Veiem que hi ha un gran diferència entre els valors de les variables **residual sugar, free sulfur dioxide i total sulfur dioxide**. També podem observar que la **mitjana de qualitat del vi és del 5.636 i la mitjana d’ alcohol contingut en el vi és de 10.20**.

Com apunt addicional, veiem que en aquesta base de dades no hi ha distinció de si el vi es blanc o roig. Per tant, no podem separar les dues tipologies sinó que les treballarem conjuntament segons la qualitat del vi (`quality`)

## Anàlisi d'elements buits i zeros

Comptarems a continuació els valors nuls per a cada columna:

````{R nuls}
colSums(is.na(B_vi))
````

Com veiem, en el nostre cas, no hi ha valors nuls presents en el dataset, probablement perquè ja s'ha passat per un pre-processament de dades abans de pujar-se a Kaggle. Tampoc eliminem cap valor en 0, ja que són valors que en el seu context tenen un sentit (per exemple, un zero a alcohol significa que el vi no conté alcohol).

## Anàlisi de valors extrems

Ara analitzarem els valors extrems, és a dir, *outliers*. Per a visualitzar-los emprarem les gràfiques Boxplot. Les dades considerades *outliers* són aquelles que surten dels "bigots", és a dir, aquelles fora del rang $$[Q_1-1.5*IR,Q_3+1.5*IRC]$$, on $IRC$ és el rang interquartilic, o el que és el mateix, $IRC=Q_3-Q_1$, i $Q_i$ és el percentil i-essim.

````{R outliers}
atributs <- names(B_vi)
p <- rainbow(12) #Colorets
k <- 1 # Per a reduir les lines de codi
for(i in 1:3){
   layout(matrix(c(1:4), nrow=1, byrow=FALSE)) #Matriu de grafiques 1x4
  
    for (j in k:(i*4)){
      boxplot(B_vi[,j], xlab=atributs[j], col=p[j]) #Boxplots
      }
  k <- 4*i+1
  }
````

Ara crearem un altre conjunt eliminant els valors extrems que veiem en el diagrama de caixa i bigots. Aquest l'emprarem per al test de saphiro per tal de veure si segueix una distribució normal o, si realitzant alguna transformació, sense outliers, segueixen una distribució normal o gaussiana.

````{R Valors Extrems}
# Llegim el document i el guardem en una altra variable
B_vi2 <- read.csv("winequality-red.csv", sep= ",", header= TRUE, dec=".")

# Convertim en valors nuls aquells que estan fora del rang interquartílic
for (i in 1:11){
  for (j in 1:1599){
    Hor <- B_vi2[,i]
    a <- quantile(Hor, 0.25, na.rm=TRUE)
    b <- quantile(Hor, 0.75, na.rm=TRUE)
    iqr <- (b-a)

    if (B_vi2[,i][j] <= (a-1.5*iqr)){
      B_vi2[,i][j] <- NA
    }
    else {if (B_vi2[,i][j] > (b+1.5*iqr)){
      B_vi2[,i][j] <- NA
    }
    }
  }
}
#Imprimim registres imputats com a valors nuls
print(colSums(is.na(B_vi2)))

# Eliminem aquelles files que tenen valors nuls
B_vi2 <- drop_na(B_vi2)
````

En la captura anterior podem observar la quantitat de registres que hem eliminat per cada columna. Aquest nou conjunt de dades servirà posteriorment en la fase d'estudi de la normalitat de dades, per tal de veure si els valors extrems alteren la distribució general de cada característica. Alternativament, podríem aplicar altres mètodes per imputar valors sobre els extrems en lloc de simplement eliminar el registre, tals com imputació per un estadístic com la mitjana, la mitja o un percentil determinat. 

De moment, conservem els dos datasets (amb i sense outliers) per a poder comparar l'efecte de la seva inclusió en la normalitat de les dades. 

# Anàlisi de les dades

## Selecció dels grups de dades
 
Com s'ha mostrat abans, el conjunt original conté 12 variables, que conceptualment podem diferenciar entre:

- Característiques objetives i mesurables del vi (conté 11 diferents variables)
- Qualitat, que és una característica definida a partir de percepcions sensorials

Per tant, agruparem les dades en funció d'inputs i outout o variable objectiu. Sobre el primer grup realitzarem una anàlisi univariant i un anàlisi per correlacions. Posteriorment, entrenarem models predictius que relacionin les diferents característiques amb l'output com a variable explicada. 

## Estudi de la normalitat de les dades

### Visualització del conjunt de dades

Una assumpció molt important que determina l'anàlisi de les dades és si les variables segueixen una distribució normal, donat que en funció de la resposta, es pot aplicar un seguit de metodologies o un altre.

Primer visualitzarem, mitjançant histogrames, com es comporten les nostres variables en relació a una distribució teòrica gaussiana:

````{R Histogrames1}
atributs <- names(B_vi)
p <- rainbow(13) #Colorets
k <- 1 # Per a reduir les lines de codi
for(i in 1:4){
  layout(matrix(c(1:3), nrow=1, byrow=FALSE)) #Matriu de grafiques 1x4

  for (j in k:(i*3)){
    hist(B_vi[,j],prob=TRUE, xlab=atributs[j], ylab="Densitat", col=p[j],
         main=paste("Histograma de ",atributs[j])) # Histograma per densitats
    curve(dnorm(x,mean=mean(B_vi[,j]),sd=sd(B_vi[,j])), from=min(B_vi[,j]),
      to=max(B_vi[,j]), add=TRUE, col=p[13], lwd=2) #Curva normal
  }
  k <- 3*i+1
}
````

Com podem apreciar en els histogrames, sembla ser que les nostres variables estan desplaçades a l'esquerra. Una transformació convenient seria realitzar la transformació logaritmica o la inversa. Mes endavant, veurem si aquesta tranformació és suficient per a que les variables segueixin una normal emprant el test de Saphiro.

De moment, acabem de visualitzar la comparació amb la normal fent les QQ-plots:

````{R Grafic qqplot}
k <- 1 # Per a reduir les lines de codi
for(i in 1:3){
   layout(matrix(c(1:4), nrow=2, byrow=FALSE)) #Matriu de grafiques 1x4
  
    for (j in k:(i*4)){
      qqnorm(B_vi[,j], main=paste("QQPlot de ",atributs[j]), col=p[j])
      qqline(B_vi[,j]) #Boxplots
      }
  k <- 4*i+1
  }

````

Analitzant els diferents **Q-Q Plots**, concloem que no semblen molt ajustats per a la normalitat: les distribucions més semblants a la gaussiana són per les variables de la densitat, el PH i el alcohol.

### Tests de bondat de l'ajust

A continuació aplicarem el tests de Shapiro i Kolmogorov, per a comprovar si les dades efectivament segueixen una distribució normal, deixant fora la variable de qualificació, ja que serà el nostre target a analitzar.

Apliquem el següent codi per calcular el p-valor del test de shapiro sobre cada variable:

````{R Funcions comprovacio normalitat}
for (i in 1:11){
  p_val <- shapiro.test(B_vi[,i])
  print(paste("El p-valor del shapiro test de", atributs[i], 
              "és:", p_val$p.value))
}
````

Els resultats anteriors mostren que les distribucions de les variables no segueixen cap normal ja que es rebutja la hipòtesi nul·la en tots els casos. 

Ara aplicarem la transformació de BoxCox per tal de poder verificar si després de la transformació les dades segueixen una distribució normal sobre el conjunt de dades on s'han eliminat els outliers:

````{R Funcions comprovacio normalitat transformades}
for (i in 1:11){
  p_val <- shapiro.test(BoxCox(B_vi2[,j], lambda = BoxCoxLambda(B_vi2[,j])))
  print(paste("El p-valor del saphito test de", atributs[i],
              "convertida és:", p_val$p.value))
}
````
Novament es rebutja la hipòtesi nul·la en tots els casos.

Apliquem també el test no paramètric de Kolmogorov-Smirnov (sobre el conjunt on no hem eliminat outliers):

````{R Funcions comprovacio normalitat Ks}
for (i in 1:11){
  p_val <- ks.test(B_vi[,i], pnorm, mean(B_vi[,i]), sd(B_vi[,i]))
  print(paste("El p-valor del Kologomorov de", atributs[i], 
              "és:", p_val$p.value))
}
````

Després dels resultats anteriors, arribem a la conclusió de que les variables, originals i transformades, no segueixen una normal. Per tant, no és convenient aplicar models que assumeixin normalitat en les dades, tals com la regressió lineal. 

A més, hem aplicat diverses transformacions, tant la logarítmica com la inversa, per tal de corregir la curtosi i la assimetria de les distribucions en relació a la distribució gaussiana. Tanmateix, cap transformació genera dades normals. 

Addicionalment, s'ha intentat realitzar una normalització per escala i per transformació de Box-Cox, però els resultats no són en cap cas satisfactoris. Alguns d'aquests resultats no els mostrem per estalvi d'espai en la documentació de la pràctica. 

### Test de homoscedasticitat

En definitiva, com les nostres dades no segueiexen una distribucio normal. Ara comprovarem l'homoscedasticitat emprant una prova de Finger-Killen per verificar si la variància és constant per la variable resposta:

````{R Filgner homoscedasticitat}
for (i in 1:11){
  p_val <- fligner.test(B_vi[,12]~ B_vi[,i])
  print(paste("El test homoscedicitat de", atributs[i], 
              "amb quality és:", p_val$p.value))
}
````

Com veiem, per a p-valors superiors al 0.05, tenim que sí presenten homoscedasticitat envers la variable resposta. Tanmateix, com les nostres dades no segueixen una distribució normal, realitzar un model de regressió lineal no és el mètode més eficaç. Ajustarem un model logístic per veure els resultats. 

## Aplicació de proves estadístiques

### Correlacions

Abans de continuar, realitzarem un estudi sobre la correlació de les nostres variables. Ens centrarem especialment en la correlació que hi ha en les variables explicatives i la variable qualificació obtinguda. Com no segueixen una distribució normal emprarem el mètode *spearman*.


````{R CORPLOT}
M = cor(B_vi, method="spearman")
corrplot(M,method="color",tl.col="black", tl.srt=30, order = "AOE",
number.cex=0.75,sig.level = 0.01, addCoef.col = "black")

````

Com podem observar, les variables que més correlació en sentit positiu (és a dir, directament relacionades) són: alcohol (0.48) i sulphates (0.38). I de manera negativa (relacionades de manera inversa) trobem volatile.acidity (-0.38).

Com és lògic pensar, els atributs que més inversament relacionats entre sí són el ph del vi amb fixed.aciditym, amb un valor de -0.71.

### Regressio Logistica

Ara realitzarem una regressió logística transformant l'atribut target, que actualment és numèric en una escala de l'1 al 10, a un atribut binari o dicotòmic, on aquelles puntuacions superiors o iguals a 6 seràn de la classe positiva (aprovades) i inferiors a aquest valor formaran part de la classe negativa (suspès). Aquesta partició es realitza perquè en el histograma anterior veiem que la majoria de les dades es troben al voltant de les valoracions 5 i 6. Les variables dependents que emprarem seran aquelles que aconsegueixen explicar certa variància total de la variable explicada "qualificacio".

El model desenvolupat serà el següent:

````{R Regresio X}
set.seed(200)
B_vi[,"quality_range"] <- cut(B_vi$quality, breaks=c(0,5.9,10), 
                              labels=c("suspens", "aprovat"))
B_vi <- select(B_vi, -quality)
m1 <- glm(quality_range ~fixed.acidity+volatile.acidity+citric.acid+
            residual.sugar+chlorides+residual.sugar+free.sulfur.dioxide+
            density+pH, data=B_vi, family=binomial)
summary(m1)
# Dibuixem
par(mfrow = c(2, 2))
plot(m1)
````

Donat que hem ajustat un model multivariant amb 11 dimensions, només analitzem els residus produits pel nostre model. En el gràfic de residius vs valors predits, observem que les dades es separen especialment en els extrem, però hi ha un bon ajust general al llarg de la recta. En el QQ plots, també podem concloure que els residus segueixen una distribució normal, un resultat que és desitjable ja que ens assegura que no tenim patrons addicionals que distorsionin la distribuciío de residus. 

D'altrabanda, el nostre model té una puntuació en termes d'AIC de 1880. Aquest valor no és directament interpretable, només podem afirmar que quant més petit millor. A banda, totes les variables tenen un valor menor al p-valor $\alpha=0.05$, a excepció del chlorides i free.sulfur.dioxide. Resulta convenient eliminar aquests atributs si ajustem un altre model logístic.

Per veure com funciona el nostre model, realitzarem una comprovació gràfica mitjançant la corba ROC. Aquesta corba realitza una gràfica i segons l'àrea compresa entre la corba i la recta $y=x$, ens indica el grau de capacitat predictiva del model. La puntuació oscil·la entre 0.5 i 1, on 1 és indicatiu d'un model perfectament predictiu i 0.5 és un model on la predicció és completament aleatòria. Mostrem a continuació la corba ROC resultant del model:

````{R corba roc}
prob=predict(m1,B_vi,type="response")
r=roc(B_vi$quality_range, prob, data=B_vi)
plot(r)
auc(r)
````

Obtenim un valor de 0.767 a la corba ROC, que és indicatiu d'un model correcte. Tot i així, el model pot millorar-se aplicant feature engineering o transformant variables i eliminant atributs que no aporten capacitat explicativa a la predicció.

### Model Supervisat

Finalment, entrenarem un model supervisat del tipus arbre de decissió. Hem escollit l'algoritme C5.0. Aquest model ens realitza un diagrama d'arbre, on el resultat es decideix en funció de les regles definides per l'arbre en cada node.


````{R Model Supervisat}
set.seed(200)

# Per a graficar l'arbre
gr = expand.grid(trials = c(1, 2), 
model = c("tree"), winnow = c(TRUE, FALSE))

# Conjunt de entrenament i test
sep <- holdout(B_vi$quality_range, ratio=2/3, mode="stratified")
train <- B_vi[sep$tr,]
test <- B_vi[sep$ts,]

# A veure la distbucio
print(table(train$quality_range))

print(table(test$quality_range))

# Creacio del model
train_control<- trainControl(method="repeatedcv", number=2, repeats=5)
model <- train(quality_range~., data=train, trControl = train_control,
               method="C5.0", tuneGrid=gr)


#Apliquem el millor model posible
c5model = C5.0.default(x = select(train, -quality_range), y = train$quality_range, 
trials = model$bestTune$trials, rules = model$bestTune$model == "rules", 
control = C5.0Control(winnow = model$bestTune$winnow))

summary(c5model)
pred2 <- predict(c5model, newdata=test)
confusionMatrix(pred2, test$quality_range)

plot(c5model, subtree= 3)
````

De manera visual, el nostre arbre es difícil de llegir, pero veiem que l'alcohol té un pes significatiu en el nostre model. En els resultats observem que el p-valor és molt petit, fet indicatiu de que el model és significatiu. A més, tal i com es mostra en el digrama, les variables alcohol i sulphates són les més significatives. 

Analitzant la matriu de confusió també podem veure que hi ha 140 dades incorrectament classificades en la partició d'entrenament. En la partició de test, el model partim de 248 registres classificats com suspesos (puntuació inferior a 6) i 285 registres com a aprovats (puntuació igual o superior a 6), un total de 533 dades. En relació als falsos negatius tenim 58 registres i 78 falsos positius. Per tant, hi ha major tendència a que el model faci una predicció erronia cap a un fals positiu. L'exactitud total del model és del 0.745. 

Per últim, exportem el csv amb el dataset modificat amb les prediccions definitives:

````{R CSV EXPORT}
write.csv(B_vi, "Vins_categoritzats.csv")
````

# Conclusions

Al principi plantejàvem si podríem explicar la qualitat d'un bon vi a partir de diferents propietats fisico-químiques mesurables. 

Hem vist que les dades amb les que podem treballar estan força allunyades de les ideals per a modelitzar aquest problema amb una regressió lineal, que pren com a principal hipòtesi la normalitat de les dades. Hem aplicat diversos tractaments per tal d'ajustar-les a la distribució gaussiana, aplicant diverses transformacions (com BoxCox) o eliminant outliers, sense que els resultats milloréssin l'ajust. 

Finalment, hem optat per generar una matriu de correlacions amb el mètode d'Spearman, que no requereix normalitat. Addicionalment, hem ajustat dos models, una regressió logística i un arbre de decissió, on hem inclós totes les variables explicatives possibles i com a variable objectiu hem definit la qualitat del vi. 

En ambdos models hem obtingut una bona capacitat predictiva, cosa que demostra que les propietats fisico-químiques són explicatives de la qualitat. Addicionalment, hem vist que no totes les variables contribueixen a la predicció en la mateixa mesura, éssent l'alcohol, els sufactes i l'acidesa volàtil de les més rellevants. 

Els resultats mostren que les metologies d'anàlisi emprades han permés resoldre el problema, tot i que el model pot ser millorat amb altres tècniques més avançades i amb més qualitat de dades. 

| Contribucions 	| Firma 	|
|:---:	|:---:	|
| Investigació Prèvia 	| JMF, DCG 	|
| Redacció de les respostes 	| JMF, DCG 	|
| Desenvolupament Codi 	| JMF, DCG 	|
