---
title: 'Tipologia i cicle de vida de les dades: Practica 2'
author: "Autors: Jonathan Mir Fernández-Aramburu i Dario Cabrera Gurillo"
date: "Maig 2022"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
  pdf_document: 
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(out.width="250px", dpi=100, warning = FALSE)
```
******
# Introducció
******

Carreguem els paquets necessaris en R
```{R message=FALSE, warning=FALSE}
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require('nortest')) install.packages('nortest'); library('nortest')
if (!require('corrplot')) install.packages('corrplot'); library('corrplot')
if (!require('doBy')) install.packages('doBy'); library('doBy')
if (!require('caret')) install.packages('caret'); library('caret')
if (!require('tidyr')) install.packages('tydir'); library('tidyr')
if (!require('DescTools')) install.packages('DescTools'); library('DescTools')
if (!require('pROC')) install.packages('pROC'); library('pROC')
if (!require('rminer')) install.packages('rminer'); library('rminer')
if (!require('C50')) install.packages('C50'); library('C50')
````

******
# Descripció del dataset
******

En aquest treball realitzarem un estudi sobre el dataset [Red Wine Quality](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009), el qual tenim disponible a la plataforma de kaggle i correspon a una adaptació del dataset treobad en *UCI machine learning repository*.

El dataset conté informació de diverses variants del vi portugués “Vinho Verde”, incloent variables quantitatives com medicions Fisico-químiques i sensorials (qualitat del vi).Tanmateix per raons de privacitat i secret comercial s’exclouen dades comercials com la marca, el preu o el tipus de raïm emprat en l’elaboració dels vins. 

Aquest data set pot ser emprat per determinar quins factors fisicoquímics defineixen un bon vi, responent a les següents preguntes: 

- Hi ha una combinació específica en les propietats Fisico-químiques que facin un vi de la millor qualitat? 
- És un factor o hi ha diversos? 
- Com és relacionen entre sí? 
- Quines són les seves distribucions estadístiques?

El dataset conté 12 variables, on les 11 primeres poden considerar-se els inputs (factors Fisico-químics) i la última l’output (valoració de la qualitat del vi basada en una experiència sensorial) dins del rang $[1,10]$.

******
# Integració i selecció de dades a analitzar.
******

Donat que resulta fonamental conèixer el domini de les dades que pretenem analitzar i modelitzar passem a descriure-les a continuació:

1. **Fixed acitidy**: Quantitat d'àcids implicats al vi. La majoria dels àcids en el vi són fixos, és a dir, no s’evaporen fàcilment.

2. **volatile acidity**: Quantitat d'àcid acètic al vi, que en altes quantitats, pot provocar un gust desagradable.

3. **citric acid**: Quantitat d'àcid cítric. Concentrat en petites quantitats, pot aportar frescor i sabor als vins.

4. **residual sugar:** La quantitat de sucre remanent un cop finalitzada la fermentació. Resulta estrany trobar vins amb menys d’un gram per litre i vins amb més de 45 grams/litre són considerats dolços. 

5. **Chlorides:** Quantitat de sal en el vi.

6. **Free sulfur dioxide:** SO2 en forma lliure existent en equilibri amb el SO2 mol·lecular (dissolt com un gas), element que impedeix el creixement bacterià i l'oxidació del vi. 

7. **Total sulfur dioxide:** Quantitat total SO2. Encara que és necesari per a evitar la oxidació, en concentracions superiors als 50 ppm  desbarata el gust i l'olor del vi. 

8. **density:** Densitat del líquid en relació a la quantitat d’alcohol i sucre. Els vins solen ser un 8\% mes densos que l'aigua.

9. **pH:** Valor numèric que ens diu el grau d'acidesa o alcalinitat del vi. Descriu quan àcid o bàsic és un vi d’una escala des de 0 (molt àcid) a 14 (molt bàsic). La majoria de vins es situen entre 3 i 4. 

10. **sulphates:** Quantitat d'additiu que actua com a antibacterià i antioxidant.

11. **Alcohol:** Percentatge d'alcohol present al vi. 

12. **quality:** Variable output qualitativa basada en dades sensorials, en una escala de $[1,10]$. 

Per l’anàlisi que volem realitzar considerem que podem mantenir les 12 variables, per tant, no farem cap subselecció.

A continuació carreguem les dades:

````{R carrega de dades videojocs}
library(readr)
B_vi <- read.csv("winequality-red.csv", sep= ",", header= TRUE, dec=".")
````

## Exploració del conjunt de dades

L'exploració inicial de les dades resulta fonamental per tenir una noció del domini de cada variable.
Efectuarem a continuació una exploració preliminar del conjunt de dades:

````{R Exploracio 1}
str(B_vi)
````

Veiem que tenim un total de 1599 registres amb 12 variables.

Podem verificar a més les distribucions de les nostres variables tenint en compte el mínim, els quartils i el màxim. 

````{R Exploracio 2}
summary(B_vi)
````

Veiem que hi ha un gran diferència entre els valors de les variables **residual sugar, free sulfur dioxide i total sulfur dioxide**. També podem observar que la **mitjana de qualitat del vi és del 5.636 i la mitjana d’ alcohol contingut en el vi és de 10.20**.

Com apunt apart, veiem que en aquesta base de dades no hi ha distinció de si el vi es blanc o roig. Per tant, no podem separar les dues tipologies sinó que les treballarem conjuntament segons la qualitat del vi. 

## Analisis d'elements buits i 0

Comprovem a continuació els valors nuls per columnes:

````{R nuls}
colSums(is.na(B_vi))
````

Com veiem en el nostre cas, no tenim valors nuls. Probablement ja ha passat per un pre-processament de dades abans de pujar-se a Kaggle. Tampoc eliminem cap valor en 0, ja que són valors que en el seu context tenen un sentit.

Ara analitzarem els valors extrems, és a dir, *outliers*. Per a visualitzar-los emprarem les grafiques Boxplot. Les dades considerades *outliers* són aquelles que surten dels "bigots", és a dir, aquelles fora del rang $$[Q_1-1.5*IR,Q_3+1.5*IRC]$$, on $IRC$ és el rang interquartilic, o el que és el mateix, $IRC=Q_3-Q_1$, i $Q_i$ és el percentil i-essim.

````{R outliers}
atributs <- names(B_vi)
p <- rainbow(12) #Colorets
k <- 1 # Per a reduir les lines de codi
for(i in 1:3){
   layout(matrix(c(1:4), nrow=1, byrow=FALSE)) #Matriu de grafiques 1x4
  
    for (j in k:(i*4)){
      boxplot(B_vi[,j], xlab=atributs[j], col=p[j]) #Boxplots
      }
  k <- 4*i+1
  }
````

Ara crearem un altre conjunt eliminant els valors extrems que veiem en el diagrama de caixa i bigots. Aquest l'emprarem per al test de saphiro per tal de veure si segueix una distribució normal o, si realitzant alguna transformacio, sense outliers, segueixen una normal o gaussiana.

````{R Valors Extrems}
# Llegim el document i el guardem en un altre noma
B_vi2 <- read.csv("winequality-red.csv", sep= ",", header= TRUE, dec=".")

# Per a eliminar valors nuls seguin el rang interquartilic
for (i in 1:11){
  for (j in 1:1599){
    Hor <- B_vi2[,i]
    a <- quantile(Hor, 0.25, na.rm=TRUE)
    b <- quantile(Hor, 0.75, na.rm=TRUE)
    iqr <- (b-a)

    if (B_vi2[,i][j] <= (a-1.5*iqr)){
      B_vi2[,i][j] <- NA
    }
    else {if (B_vi2[,i][j] > (b+1.5*iqr)){
      B_vi2[,i][j] <- NA
    }
    }
  }
}
#Veiem valors nuls
print(colSums(is.na(B_vi2)))

# Eliminem aquelles files que tenen valors nuls
B_vi2 <- drop_na(B_vi2)
````
En aquest cas, hem aplicat una eliminacio de tots els valors que hem detectat com a outliers seguint els parametres del boxplot. Aquestes dades sols ens serviran al moment d'aplicar el test de Saphiro.test, per a veure si aquestes dades funcionen millor o no. Podriem aplicar metodes de mediana o mitjana de dades per a no eliminar tantes, pero per la llargaria d'aquest treball no podem realitzar tots els procediments que haguerem desitjat. EXPLICAR MILLOR ESTO. SOLS LES HEM ELIMINAT PER A VEURE SI MILLOR LA NORMALITAT DE LES DADES

***********
# Analisis de les dades
***********

## Selecció dels grups de dades
 
FALTA, S'HAN SELECCIONAT TOTES EN REALITAT

## Estudi de la normalitat de les dades

### Visualització del conjunt de dades

Una assumpció molt important que determina l'anàlisi de les dades és si les variables segueixen una distribució normal, donat que en funció de la resposta, es pot aplicar un seguit de metodologies o un altre.


Primer visualitzarem, mitjançant histogrames, com es comporten les nostres variables en relació a una distribució teòrica gaussiana:

````{R Histogrames1}
atributs <- names(B_vi)
p <- rainbow(13) #Colorets
k <- 1 # Per a reduir les lines de codi
for(i in 1:4){
  layout(matrix(c(1:3), nrow=1, byrow=FALSE)) #Matriu de grafiques 1x4

  for (j in k:(i*3)){
    hist(B_vi[,j],prob=TRUE, xlab=atributs[j], ylab="Densitat", col=p[j],
         main=paste("Histograma de ",atributs[j])) # Histograma per densitats
    curve(dnorm(x,mean=mean(B_vi[,j]),sd=sd(B_vi[,j])), from=min(B_vi[,j]),
      to=max(B_vi[,j]), add=TRUE, col=p[13], lwd=2) #Curva normal
  }
  k <- 3*i+1
}
````

Com podem apreciar en els histogrames, sembla ser que les nostres variables estan desplaçades a l'esquerra, aleshores una transformació convenient seria realitzar la transformació logaritmica o la inversa. Mes endavant, veurem si aquesta tranformació és suficient per a que les variables segueixin una normal emprant el test de Saphiro.

Per ara acabem de visualitzar la comparació en la normal fent gràfiques QQ.

````{R Grafic qqplot}
k <- 1 # Per a reduir les lines de codi
for(i in 1:3){
   layout(matrix(c(1:4), nrow=2, byrow=FALSE)) #Matriu de grafiques 1x4
  
    for (j in k:(i*4)){
      qqnorm(B_vi[,j], main=paste("QQPlot de ",atributs[j]), col=p[j])
      qqline(B_vi[,j]) #Boxplots
      }
  k <- 4*i+1
  }

````

Fixant-nos en els diferents **Q-Q Plots**, no semblen molt ajustats per a la normalitat: les distribucions més semblants a la gaussiana són per les variables de la densitat, el PH i el alcohol.

### Comprovacio teorica amb tests

A continuació aplicarem el tests de Shapiro i Kolmogorov, per a comprovar si les dades efectivament segueixen una distribució normal, deixant fora la variable de qualificació, ja que serà el nostre target a analitzar.

````{R Funcions comprovacio normalitat}
for (i in 1:11){
  p_val <- shapiro.test(B_vi[,i])
  print(paste("El p-valor del shapiro test de", atributs[i], 
              "és:", p_val$p.value))
}
````

Queda patent que si no es tracten els valors extrems, les distribucions de les variables no segueixen cap normal ja que es rebutja la hipòtesi nul·la en tots els casos. 

Ara aplicarem la transformació de BoxCox per tal de poder verificar que després de la transformació les dades segueixen una distribució normal:

````{R Funcions comprovacio normalitat transformades}
for (i in 1:11){
  p_val <- shapiro.test(BoxCox(B_vi2[,j], lambda = BoxCoxLambda(B_vi2[,j])))
  print(paste("El p-valor del saphito test de", atributs[i],
              "convertida és:", p_val$p.value))
}
````

Apliquem també el test no paramètric de Kolmogorov-Smirnov:

````{R Funcions comprovacio normalitat Ks}
for (i in 1:11){
  p_val <- ks.test(B_vi[,i], pnorm, mean(B_vi[,i]), sd(B_vi[,i]))
  print(paste("El p-valor del Kologomorov de", atributs[i], 
              "és:", p_val$p.value))
}
````

Després dels resultats anteriors, arribem a la conclusió de que les variables no segueixen una normal. Per tant, no és convenient aplicar models que assumeixin normalitat en les dades, tals com la regressió lineal. 

A més, hem aplicat diverses transformacions, tant la logarítmica com la inversa, per tal de corregir la curtosi i la assimetria de les distribucions en relació a la distribució gaussiana. Tanmateix, cap transformació genera dades normals. 

Addicionalment, s'ha intentat realitzar una normalització per escala i per transformació de Box-Cox, però els resultats no són en cap cas satisfactoris. 

### Test de homoscedasticitat

En definitiva, com les nostres dades no segueiexen una distribucio normal, comprovarem l'homoscedasticitat emprant una prova de Finger-Killen per verificar si la variància és constant per la variable resposta:

````{R Filgner homoscedasticitat}
for (i in 1:11){
  p_val <- fligner.test(B_vi[,12]~ B_vi[,i])
  print(paste("El test homoscedicitat de", atributs[i], 
              "amb quality és:", p_val$p.value))
}
````

Com veiem, per a p-valors superiors al 0.05, tenim que sí presenten homoscedasticitat envers la variable resposta. Tanmateix, com les nostres dades no segueixen una distribució normal, realitzar un model de regressió lineal no és el mètode més eficaç. Ajustarem un model logístic per veure els resultats. 

## Aplicació de proves estadístiques

### Correlacions

Abans de continuar, realitzarem un estudi sobre la correlació de les nostres variables. Ens centrarem especialment en la correlacio que hi ha en les variables explicatives i la variable qualificacio obtinguda. Com no segueixen una distribució normal emprarem el mètode *spearman*.


````{R CORPLOT}
M = cor(B_vi, method="spearman")
corrplot(M,method="color",tl.col="black", tl.srt=30, order = "AOE",
number.cex=0.75,sig.level = 0.01, addCoef.col = "black")

````

Com podem observar, les variables que més correlació tenen són de manera positiva (és a dir, directament relacionades) són: alcohol (0.48) i sulphates (0.38). I de manera negativa (relacionades de manera inversa) trobem volatile.acidity (-0.38).

Com és lògic pensar, els atributs que més relacionats entre sí són el ph del vi amb fixed.aciditym, amb un valor de -0.71.

### Regressio Logistica

Ara realitzarem una regressió logística transformat l'atribut target, que actualment és numèric en una escala de l'1 al 10, a un atribut binari o dicotòmic, on aquelles puntuacions superiors o iguals a 6 seràn de la classe positiva (aprovades) i inferiors a aquest valor formaran part de la classe negativa (suspès). Aquesta partició es realitza perquè en el histograma anterior veiem que la majoria de les dades es troben al voltant de les valoracions 5 i 6. Les variables dependents que emprarem seran aquelles que aconsegueixen explicar certa variància total de la variable explicada "qualificacio".

El model desenvolupat serà el següent:

````{R Regresio X}
set.seed(200)
B_vi[,"quality_range"] <- cut(B_vi$quality, breaks=c(0,5.9,10), 
                              labels=c("suspens", "aprovat"))
B_vi <- select(B_vi, -quality)
m1 <- glm(quality_range ~fixed.acidity+volatile.acidity+citric.acid+
            residual.sugar+chlorides+residual.sugar+free.sulfur.dioxide+
            density+pH, data=B_vi, family=binomial)
summary(m1)
# Dibuixem
par(mfrow = c(2, 2))
plot(m1)
````

DARIO: Com tenim una funcio de regresio logistica molt gran, parlem de 10 dimensions en el nostre cas, sols podem analitzar els residus produits per el nostre model. En la de residus vs predictius, observer que les dades se separen un poc a les vores, pero en general estan tots al voltant de la recta. En el QQ plot veiem que els residus segueixen una normal, cosa que ens afavorix correctament.

Com veiem, el nostre model té una puntuació en termes d'AIC de 1880. Aquest valor no és directament interpretable, només podem afirmar que quant més petit millor. A banda, totes les variables tenen un valor menor al p-valor $\alpha=0.05$, a excepció del chlorides i free.sulfur.dioxide. Resulta convenient eliminar aquests atributs si ajustem un altre model logístic.

Per veure com funciona el nostre model, realitzarem una comprovació gràfica mitjançant la corba ROC. Aquesta corba realitza una gràfica i segons l'àrea compresa entre la corba i la recta $y=x$, ens indica el grau de capacitat predictiva del model. La puntuació oscil·la entre 0.5 i 1, on 1 és indicatiu d'un model perfectament predictiu i 0.5 és un model on la predicció és completament aleatòria. 

Calculem a continuació la corba ROC:

````{R corba roc}
prob=predict(m1,B_vi,type="response")
r=roc(B_vi$quality_range, prob, data=B_vi)
plot(r)
auc(r)
````


Obtenim un valor de 0.767 a la corba ROC, que és indicatiu d'un model correcte. Tot i així, el model pot millorar-se aplicant feature engineering o transformant variables i eliminant atributs que no aporten capacitat explicativa a la predicció.

### Model Supervisat

Finalment, entrenarem un model supervisat del tipus arbre de decissió. Hem escollit el C5.0. Aquest model ens realitza un diagrama d'arbre, on el resultat es decideix en funció de les regles definides per l'arbre en cada node.


````{R Model Supervisat}
set.seed(200)

# Per a graficar l'arbre
gr = expand.grid(trials = c(1, 2), 
model = c("tree"), winnow = c(TRUE, FALSE))

# Conjunt de entrenament i test
sep <- holdout(B_vi$quality_range, ratio=2/3, mode="stratified")
train <- B_vi[sep$tr,]
test <- B_vi[sep$ts,]

# A veure la distbucio
print(table(train$quality_range))

print(table(test$quality_range))

# Creacio del model
train_control<- trainControl(method="repeatedcv", number=2, repeats=5)
model <- train(quality_range~., data=train, trControl = train_control,
               method="C5.0", tuneGrid=gr)


#Apliquem el millor model posible
c5model = C5.0.default(x = select(train, -quality_range), y = train$quality_range, 
trials = model$bestTune$trials, rules = model$bestTune$model == "rules", 
control = C5.0Control(winnow = model$bestTune$winnow))

summary(c5model)
pred2 <- predict(c5model, newdata=test)
confusionMatrix(pred2, test$quality_range)

plot(c5model, subtree= 3)
````

De manera visual, el nostre arbre es difícil de llegir, pero veiem que l'alcohol té un pes significatiu en el nostre model. En els resultats observem que el p-valor és molt petit, fet indicatiu de que el model és significatiu. A més, tal i com es mostra en el digrama, les variables alcohol i sulphates són les més significatives. 

Analitzant la matriu de confusió també podem veure que hi ha 140 dades incorrectament classificades en la partició d'entrenament. En la partició de test, el model partim de 248 registres classificats com suspesos (puntuació inferior a 6) i 285 registres com a aprovats (puntuació igual o superior a 6), un total de 533 dades. En relació als falsos negatius tenim 58 registres i 78 falsos positius. Per tant, hi ha major tendència a que el model faci una predicció erronia cap a un fals positiu. L'exactitud total del model és del 0.745. 

Per ultim exportem el csv amb el dataset modificat amb les prediccions definitives:

````{R CSV EXPORT}
write.csv(B_vi, "Vins_categoritzats.csv")
````


| Contribucions 	| Firma 	|
|:---:	|:---:	|
| Investigació Prèvia 	| JMF, DCG 	|
| Redacció de les respostes 	| JMF, DCG 	|
| Desenvolupament Codi 	| JMF, DCG 	|
